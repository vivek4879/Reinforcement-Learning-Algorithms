# Reinforcement Algorithms

This Respository consists of solving mutiple environments using Reinforcement algorithms.

## Environments:
1. CartPole-V1
2. Lunar Landing
3. Bi-Pedal Walker

## Algorithms:
1. Q-Learning
2. Double Q-Learning
3. SARSA
4. A2C


During my ML study, I stumbled on reward-based learning similar to how humans learn, famously coined as Reinforcement learning(RL). I had read about Alpha Go defeating human players in Go and chess, but I needed to know how. My fascination for RL continued to rise after I watched the video about agents interacting and learning in the hide&seek environment, with both hiders and seekers learning from each other after each move in more than a million iterations and finding patterns in the game which even the developer didn't plan to create! This piqued my curiosity, and I began with algorithms in RL, such as Q-learning and SARSA, and then moved on to DQN, the Actor-Critic model, and took this to the next step by developing these algorithms from scratch in Python and leveraged the principles of OOPs to extend each algorithm to multiple agents in different environments. To delve deeper, I studied a couple of relevant research papers related to AlphaGo, and my favorite one talked about using RL (MuZero architecture) to optimize the extensively used VP9 video compression algorithm impacting all streaming websites, thus savings Petabytes of memory and bandwidth on the network. I took on this challenge as the sole developer and implemented this architecture by re-reading the paper multiple times, correcting my algorithmic understanding, followed by hyperparameter tuning resulting in noteworthy results compared to VP9 compressions PSNR results of libvpx library when tested on the Youtube UGC dataset. I plan to release this as an open-source project for collaborating with countless talented Computer Scientists across the world and challenge the status quo of VP9 compression engine to save costs as well as bandwidth.
